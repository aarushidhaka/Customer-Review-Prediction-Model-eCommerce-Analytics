# -*- coding: utf-8 -*-
"""AIP-Group 15

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b8ViMsvrm7i4q2l0kTt7kYSXQpj39FO5
"""

import zipfile
import os
import pandas as pd
import numpy as np

# Step 1: Unzip the uploaded file
zip_path = '/content/dataset.zip'  # Path to your uploaded dataset.zip
extraction_path = '/mnt/data/dataset/'

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extraction_path)

# List the extracted files to understand the content
ecommerce_path = os.path.join(extraction_path, 'brazilian-ecommerce')
ecommerce_files = os.listdir(ecommerce_path)

# Step 2: Load relevant datasets
customers_df = pd.read_csv(os.path.join(ecommerce_path, 'olist_customers_dataset.csv'))
orders_df = pd.read_csv(os.path.join(ecommerce_path, 'olist_orders_dataset.csv'))
order_reviews_df = pd.read_csv(os.path.join(ecommerce_path, 'olist_order_reviews_dataset.csv'))
order_items_df = pd.read_csv(os.path.join(ecommerce_path, 'olist_order_items_dataset.csv'))
products_df = pd.read_csv(os.path.join(ecommerce_path, 'olist_products_dataset.csv'))
category_translation_df = pd.read_csv(os.path.join(ecommerce_path, 'product_category_name_translation.csv'))
order_payments_df = pd.read_csv(os.path.join(ecommerce_path, 'olist_order_payments_dataset.csv'))
# Extract payment value column
order_payments_df = order_payments_df[['order_id', 'payment_value']]

# Step 3: Merge the datasets, ensuring 'order_status' is included
merged_df = pd.merge(orders_df, customers_df, on='customer_id', how='inner')
merged_df = pd.merge(merged_df, order_reviews_df, on='order_id', how='inner')
merged_df = pd.merge(merged_df, order_items_df, on='order_id', how='inner')
merged_df = pd.merge(merged_df, products_df, on='product_id', how='inner')
# Merge payment data with the existing dataset before filtering
merged_df = pd.merge(merged_df, order_payments_df, on='order_id', how='left') # Merging payment data before filtering

# Now we should be able to filter:
merged_df = merged_df[merged_df['order_status'] == 'delivered']

# Step 4: Select relevant columns as per the user's requirements
selected_columns = [
    'order_id', 'customer_unique_id', 'review_id', 'review_score',
    'customer_state', 'price','payment_value','product_category_name', 'order_delivered_customer_date', 'order_purchase_timestamp'
]
merged_df = merged_df[selected_columns]

# Step 5: Rename columns for better readability
merged_df.rename(columns={
    'order_delivered_customer_date': 'delivery_date',
    'order_purchase_timestamp': 'purchase_timestamp',
    'product_category_name': 'product_category_name_english'
}, inplace=True)

# Step 6: Convert 'purchase_timestamp' and 'delivery_date' to datetime format to calculate 'delivery_time_days'
merged_df['purchase_timestamp'] = pd.to_datetime(merged_df['purchase_timestamp'])
merged_df['delivery_date'] = pd.to_datetime(merged_df['delivery_date'])

# Calculate the delivery time in days
merged_df['delivery_time_days'] = (merged_df['delivery_date'] - merged_df['purchase_timestamp']).dt.days

# Step 7: Data Cleaning - Remove missing values and duplicates
merged_df.dropna(inplace=True)
merged_df.drop_duplicates(inplace=True)
print(merged_df.isnull().sum())

# Step 8: Feature Engineering
# Number of Items - count of items per order
merged_df['number_of_items'] = merged_df.groupby('order_id')['order_id'].transform('count')

# Step 9: Merge with "olist_orders_dataset" to get 'order_delivered_customer_date' and 'order_estimated_delivery_date'
# Merge the additional columns with your final dataset (merged_df)
merged_df = pd.merge(merged_df, orders_df[['order_id', 'order_delivered_customer_date', 'order_estimated_delivery_date']],
                     on='order_id', how='left')

# Step 10: Create a new column that compares 'order_delivered_customer_date' and 'order_estimated_delivery_date'
# Convert 'order_delivered_customer_date' and 'order_estimated_delivery_date' to datetime objects
merged_df['order_delivered_customer_date'] = pd.to_datetime(merged_df['order_delivered_customer_date'])
merged_df['order_estimated_delivery_date'] = pd.to_datetime(merged_df['order_estimated_delivery_date'])

#  Handle cases where delivery dates are exactly the same or close
# Define a small tolerance window (e.g., 1 day) to consider "on time"
tolerance = pd.Timedelta(days=1)
merged_df['delivery_status'] = np.where(
    (merged_df['order_delivered_customer_date'] - merged_df['order_estimated_delivery_date']).abs() <= tolerance,
    'on time',
    np.where(merged_df['order_delivered_customer_date'] < merged_df['order_estimated_delivery_date'], 'early', 'delayed')
)

# Convert 'delivery_status' to a categorical type with specific order
merged_df['delivery_status'] = merged_df['delivery_status'].astype(pd.CategoricalDtype(categories=['early', 'on time', 'delayed'], ordered=True))

# Step 11: Merge the translation dataframe with the main merged dataframe
merged_df = pd.merge(merged_df, category_translation_df, how='left', left_on='product_category_name_english', right_on='product_category_name')

# Update the product category name column to the translated English value
merged_df['product_category_name_english'] = merged_df['product_category_name_english_y']

# Drop unnecessary columns
merged_df.drop(columns=['product_category_name', 'product_category_name_english_y', 'product_category_name_english_x',
                        'review_id', 'order_id','delivery_date','purchase_timestamp', 'number_of_items',
                        'order_delivered_customer_date', 'order_estimated_delivery_date'], inplace=True)

# repalce the missing value in product_category_name_english with Unspecified
merged_df['product_category_name_english'] = merged_df['product_category_name_english'].fillna('Unspecified')

# Step 12: Save the final cleaned and feature-engineered dataset to an Excel file
output_path_updated = "/mnt/data/cleaned_feature_engineered_dataset_final.xlsx"
merged_df.to_excel(output_path_updated, index=False)

# Provide download link for the updated dataset
output_path_updated

# Import the necessary module for downloading files in Google Colab.
from google.colab import files

# Path to the saved Excel file
output_path_updated = '/mnt/data/cleaned_feature_engineered_dataset_final.xlsx'

# Download the file using the files.download() function.
files.download(output_path_updated)

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
# Calculate the average review score by delivery status
delivery_status_analysis = merged_df.groupby('delivery_status')['review_score'].mean()
print("Average Review Score by Delivery Status:")
print(delivery_status_analysis)

# Visualize the distribution of review scores for each delivery status
plt.figure(figsize=(10, 6)) # Now plt is defined and can be used
sns.boxplot(x='delivery_status', y='review_score', data=merged_df, order=['early', 'on time', 'delayed'])
plt.title('Review Scores by Delivery Status')
plt.xlabel('Delivery Status')
plt.ylabel('Review Score')
plt.xticks(rotation=0)
plt.grid(True)
plt.show()

#  Statistical Test (ANOVA)
# Extract review scores for each delivery status category
early_reviews = merged_df[merged_df['delivery_status'] == 'early']['review_score']
on_time_reviews = merged_df[merged_df['delivery_status'] == 'on time']['review_score']
delayed_reviews = merged_df[merged_df['delivery_status'] == 'delayed']['review_score']

#Check if there are any missing values in the state and product category columns
print(merged_df[['customer_state', 'product_category_name_english', 'review_score']].isnull().sum())

#State-wise review score analysis
state_review_score = merged_df.groupby('customer_state')['review_score'].mean().sort_values(ascending=False)
print("Average Review Score by State:")
print(state_review_score)

# Visualize the state-wise review scores
plt.figure(figsize=(12, 6))
sns.barplot(x=state_review_score.index, y=state_review_score.values, palette='viridis')
plt.title('Average Review Score by State')
plt.xlabel('State')
plt.ylabel('Average Review Score')
plt.xticks(rotation=90)
plt.grid(True)
plt.show()

# Further visualization (Boxplot for understanding distribution)
# State-wise review score distribution
plt.figure(figsize=(12, 6))
sns.boxplot(x='customer_state', y='review_score', data=merged_df, palette='viridis')
plt.title('Review Score Distribution by State')
plt.xlabel('State')
plt.ylabel('Review Score')
plt.xticks(rotation=90)
plt.grid(True)
plt.show()

# Product category-wise review score analysis
product_review_score = merged_df.groupby('product_category_name_english')['review_score'].mean().sort_values(ascending=False)
print("Average Review Score by Product Category:")
print(product_review_score)

# Visualize the product category-wise review scores
plt.figure(figsize=(12, 6))
sns.barplot(x=product_review_score.index, y=product_review_score.values, palette='viridis')
plt.title('Average Review Score by Product Category')
plt.xlabel('Product Category')
plt.ylabel('Average Review Score')
plt.xticks(rotation=90)
plt.grid(True)
plt.show()

# Product category-wise review score distribution
plt.figure(figsize=(12, 6))
sns.boxplot(x='product_category_name_english', y='review_score', data=merged_df, palette='viridis')
plt.title('Review Score Distribution by Product Category')
plt.xlabel('Product Category')
plt.ylabel('Review Score')
plt.xticks(rotation=90)
plt.grid(True)
plt.show()

# Average Price by Product Category
product_price = merged_df.groupby('product_category_name_english')['price'].mean().sort_values(ascending=False)

plt.figure(figsize=(12, 6))
sns.barplot(x=product_price.index, y=product_price.values, palette='viridis')
plt.title('Average Price by Product Category')
plt.xlabel('Product Category')
plt.ylabel('Average Price')
plt.xticks(rotation=90)
plt.grid(True)
plt.show()

# Boxplot - Price Distribution by Product Category
plt.figure(figsize=(12, 6))
sns.boxplot(x='product_category_name_english', y='price', data=merged_df, palette='viridis')
plt.title('Price Distribution by Product Category')
plt.xlabel('Product Category')
plt.ylabel('Price')
plt.xticks(rotation=90)
plt.grid(True)
plt.show()

# Step 6:Average Payment Value by Product Category
product_payment = merged_df.groupby('product_category_name_english')['payment_value'].mean().sort_values(ascending=False)

plt.figure(figsize=(12, 6))
sns.barplot(x=product_payment.index, y=product_payment.values, palette='viridis')
plt.title('Average Payment Value by Product Category')
plt.xlabel('Product Category')
plt.ylabel('Average Payment Value')
plt.xticks(rotation=90)
plt.grid(True)
plt.show()


# Boxplot - Payment Value Distribution by Product Category
plt.figure(figsize=(12, 6))
sns.boxplot(x='product_category_name_english', y='payment_value', data=merged_df, palette='viridis')
plt.title('Payment Value Distribution by Product Category')
plt.xlabel('Product Category')
plt.ylabel('Payment Value')
plt.xticks(rotation=90)
plt.grid(True)
plt.show()

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import precision_recall_fscore_support, accuracy_score

# Dealing with Categorical Data and classify review_score
merged_df['review_category'] = merged_df['review_score'].apply(lambda x:1 if x>=4 else 0)

from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
merged_df['product_category_name_english_numeric'] = encoder.fit_transform(merged_df['product_category_name_english'])
merged_df['customer_state_numeric'] = encoder.fit_transform(merged_df['customer_state'])
merged_df['delivery_status_numeric'] = encoder.fit_transform(merged_df['delivery_status'])
merged_df['review_category'] = encoder.fit_transform(merged_df['review_category'])

# set x and y
features = ['price', 'payment_value', 'delivery_status_numeric', 'delivery_time_days', 'customer_state_numeric','product_category_name_english_numeric']

X = merged_df[features]
y = merged_df['review_category']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4567, stratify=y)

print("X_train shape:", X_train.shape)
print("X_test shape:", X_test.shape)
print("y_train shape:", y_train.shape)
print("y_test shape:", y_test.shape)

# Random Forest - regression
from sklearn.ensemble import RandomForestClassifier as RF
from sklearn.metrics import precision_recall_fscore_support, accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
from sklearn.metrics import ConfusionMatrixDisplay as CM

# Create and train the model
RF_algo = RF()
RF_model = RF_algo.fit(X_train, y_train)

models = [RF_model]
names = ['Random Forest']

# Evaluate model performance
for i in range(len(models)):
    print(f"Model: {names[i]}")

# Evaluate performance on training data
predict_train = models[i].predict(X_train)
precision_train, recall_train, f1_train, _ = precision_recall_fscore_support(y_train, predict_train, average='macro')
accuracy_train = accuracy_score(y_train, predict_train)
print(f"Train Macro Precision: {precision_train:.3f}")
print(f"Train Macro Recall: {recall_train:.3f}")
print(f"Train Macro F1-score: {f1_train:.3f}")
print(f"Train Accuracy: {accuracy_train:.3f}")

# Evaluate performance on test data
predict_test = models[i].predict(X_test)
precision_test, recall_test, f1_test, _ = precision_recall_fscore_support(y_test, predict_test, average='macro')
accuracy_test = accuracy_score(y_test, predict_test)
print(f"Test Macro Precision: {precision_test:.3f}")
print(f"Test Macro Recall: {recall_test:.3f}")
print(f"Test Macro F1-score: {f1_test:.3f}")
print(f"Test Accuracy: {accuracy_test:.3f}")
print("\n")

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

y_pred = rf_model.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"R-squared (R²): {r2:.2f}")


feature_importances = pd.DataFrame({
    'Feature': features,
    'Importance': rf_model.feature_importances_
}).sort_values(by='Importance', ascending=False)


plt.figure(figsize=(8, 5))
plt.bar(feature_importances['Feature'], feature_importances['Importance'], color='skyblue')
plt.title('Feature Importance')
plt.xlabel('Feature')
plt.ylabel('Importance')
plt.show()

print("Random Forest Confusion Matrix")
predict = RF_model.predict(X_test)
CM.from_predictions(y_test, predict)

# Random Forest using calssification

from sklearn.ensemble import RandomForestClassifier as RF
from sklearn.metrics import precision_recall_fscore_support, accuracy_score, ConfusionMatrixDisplay
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.metrics import ConfusionMatrixDisplay as CM
# Modeling and Evaluation
# Step 1: Train the Random Forest model with default parameters
RF_algo = RF(random_state=4567)
RF_model = RF_algo.fit(X_train, y_train)

# Step 2: Evaluate the model on training data
train_predict = RF_model.predict(X_train)
train_precision, train_recall, train_f1, _ = precision_recall_fscore_support(y_train, train_predict, average='macro')
print("\nTraining Data Performance:")
print(f"Macro Precision: {train_precision:.3f}")
print(f"Macro Recall: {train_recall:.3f}")
print(f"Macro F1-score: {train_f1:.3f}")
train_accuracy = accuracy_score(y_train, train_predict)
print(f"Accuracy: {train_accuracy:.3f}")


# Step 3: Evaluate the model on test data
test_predict = RF_model.predict(X_test)
test_precision, test_recall, test_f1, _ = precision_recall_fscore_support(y_test, test_predict, average='macro')
print("\nTest Data Performance:")
print(f"Macro Precision: {test_precision:.3f}")
print(f"Macro Recall: {test_recall:.3f}")
print(f"Macro F1-score: {test_f1:.3f}")
test_accuracy = accuracy_score(y_test, test_predict)
print(f"Accuracy: {test_accuracy:.3f}")


# Step 4: Confusion Matrix for Test Data
print("\nRandom Forest Confusion Matrix (Test Data):")
ConfusionMatrixDisplay.from_predictions(y_test, test_predict)

# Step 5: Feature Importance
print("\nFeature Importances:")
feature_importances = pd.DataFrame({
    'Feature': X_train.columns,
    'Importance': RF_model.feature_importances_
}).sort_values(by='Importance', ascending=False)
print(feature_importances)

# Step 6: Feature Importance Visualization
plt.figure(figsize=(8, 6))
plt.bar(feature_importances['Feature'], feature_importances['Importance'], color='skyblue')
plt.title("Feature Importance", fontsize=14, fontweight="bold")
plt.xlabel("Features", fontsize=12)
plt.ylabel("Importance", fontsize=12)
plt.xticks(rotation=45, ha="right")
plt.tight_layout()
plt.show()

# Modeling and Evaluation by GBDT and XGB
from sklearn.ensemble import GradientBoostingClassifier as GBDT
from xgboost import XGBClassifier as XGB
from sklearn.metrics import precision_recall_fscore_support
from sklearn.metrics import mean_squared_error, r2_score

GBDT_algo = GBDT()
GBDT_model = GBDT_algo.fit(X_train, y_train)

XGB_algo = XGB()
XGB_model = XGB_algo.fit(X_train, y_train)

models = [GBDT_model, XGB_model]
names = ['GBDT', 'XGBDT']
# Evaluate the model on training data
for i in range(2):
  print(f"Model: {names[i]}")
  train_predict = models[i].predict(X_train)
  train_precision, train_recall, train_f1, _ = precision_recall_fscore_support(y_train, train_predict, average='macro')
  print("\nTraining Data Performance:")
  print(f"Macro Precision: {train_precision:.3f}")
  print(f"Macro Recall: {train_recall:.3f}")
  print(f"Macro F1-score: {train_f1:.3f}")
  train_accuracy = accuracy_score(y_train, train_predict)
  print(f"Accuracy: {train_accuracy:.3f}")

# Evaluate the model on test data
test_predict = models[i].predict(X_test)
test_precision, test_recall, test_f1, _ = precision_recall_fscore_support(y_test, test_predict, average='macro')

print("\nTest Data Performance:")
print(f"Macro Precision: {test_precision:.3f}")
print(f"Macro Recall: {test_recall:.3f}")
print(f"Macro F1-score: {test_f1:.3f}")
test_accuracy = accuracy_score(y_test, test_predict)
print(f"Accuracy: {test_accuracy:.3f}")
print("\n")

# GBDT Confusion Matrix
from sklearn.metrics import ConfusionMatrixDisplay as CM
print("GBDT Confusion Matrix")
predict_GBDT = GBDT_model.predict(X_test)
print(CM.from_predictions(y_test, predict_GBDT))

# XGBDT Confusion Matrix
print("XGBDT Confusion Matrix")
predict_XGB = XGB_model.predict(X_test)
print(CM.from_predictions(y_test, predict_XGB))

# Feature Importance for GBDT and XGB
print("\nFeature Importances for GBDT and XGB:")

# Feature Importance for GBDT
gbdt_feature_importances = pd.DataFrame({
    'Feature': X_train.columns,
    'Importance': GBDT_model.feature_importances_
}).sort_values(by='Importance', ascending=False)

print("GBDT Feature Importances:")
print(gbdt_feature_importances)

# Feature Importance for XGB
xgb_feature_importances = pd.DataFrame({
    'Feature': X_train.columns,
    'Importance': XGB_model.feature_importances_
}).sort_values(by='Importance', ascending=False)

print("XGB Feature Importances:")
print(xgb_feature_importances)

# Feature Importance Visualization for GBDT
plt.figure(figsize=(8, 6))
plt.bar(gbdt_feature_importances['Feature'], gbdt_feature_importances['Importance'], color='skyblue')
plt.title("GBDT Feature Importance", fontsize=14, fontweight="bold")
plt.xlabel("Features", fontsize=12)
plt.ylabel("Importance", fontsize=12)
plt.xticks(rotation=45, ha="right")
plt.tight_layout()
plt.show()

# Feature Importance Visualization for XGB
plt.figure(figsize=(8, 6))
plt.bar(xgb_feature_importances['Feature'], xgb_feature_importances['Importance'], color='skyblue')
plt.title("XGB Feature Importance", fontsize=14, fontweight="bold")
plt.xlabel("Features", fontsize=12)
plt.ylabel("Importance", fontsize=12)
plt.xticks(rotation=45, ha="right")
plt.tight_layout()
plt.show()

# Get the predict of X_test by XGB
predicted_review_score = XGB_model.predict(X_test)
merged_df.loc[X_test.index, 'predicted_review_score'] = predicted_review_score

import pandas as pd
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, precision_recall_fscore_support, mean_squared_error, r2_score

models = [rf_model, RF_model, GBDT_model, XGB_model]
model_names = ['Random Forest-regression', 'Random Forest-classification', 'GBDT', 'XGB']

metrics_list = []

for model, name in zip(models, model_names):
    test_predict = model.predict(X_test)
    if name in ['Random Forest-regression']:
        test_mse = mean_squared_error(y_test, test_predict)
        test_r2 = r2_score(y_test, test_predict)
        metrics_list.append({
            'Model': name,
            'MSE': test_mse,
            'r2': test_r2
        })

    else:
        test_accuracy = accuracy_score(y_test, test_predict)
        test_precision, test_recall, test_f1, _ = precision_recall_fscore_support(y_test, test_predict, average='macro')
        metrics_list.append({
            'Model': name,
            'Accuracy': test_accuracy,
            'Macro Precision': test_precision,
            'Macro Recall': test_recall,
            'Macro F1 Score': test_f1
        })

metrics_df = pd.DataFrame(metrics_list)

metrics_df.to_csv('models_performance_metrics.csv', index=False)
from google.colab import files
files.download('models_performance_metrics.csv')

# Save the predict of X_test
output_path = "/mnt/data/cleaned_and_model_results.csv"
merged_df.to_csv(output_path, index=False)
from google.colab import files
files.download(output_path)